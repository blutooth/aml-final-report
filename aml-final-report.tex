%% LyX 2.1.2.2 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=1cm,bmargin=2cm,lmargin=2cm,rmargin=2cm}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{esint}

% Misc
\newcommand{\todo}[1]{}
\renewcommand{\todo}[1]{{\color{red} TODO\@: {#1}}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% A simple dot to overcome graphicx limitations
\newcommand{\lyxdot}{.}

\makeatother

\usepackage{babel}

\begin{document}

\title{Firefly Monte Carlo: Exact MC with data subsets}
\author{Feynman Liang, Max Chamberlin, Kai Xu}
%
\maketitle

\tableofcontents

\section{Introduction}

Many methods in Bayesian inference involve computing the likelihood
$L(\theta)$ of parameters $\theta$ over iid observations
$X=\{x_{n}\}_{n=1}^{N}$, defined as

\begin{equation}\label{eq:likelihood}
  L(\theta)=P(X|\theta)=\prod_{n=1}^{N}P(x_{n}|\theta)=\prod_{n=1}^{N}L_{n}(\theta)
\end{equation}

For example, Monte Carlo Markov Chain (MCMC) are a class of methods often
used to sample posterior distributions $P(\theta | X)$ with intractable
partition functions $Z = \int P(X|\theta) P(\theta) d\theta$.
When performing Metropolis-Hastings MCMC, at each iteration we need to compute
the acceptance probability

\[
A(\theta'|\theta)=\min\left\{ 1,\frac{q(\theta|\theta')L(\theta')P(\theta')}{q(\theta'|\theta)L(\theta)P(\theta)}\right\}
\]

This means that each iteration requires at least one evaluation $L(\theta')$
of the likelihood over all $N$ points ($L(\theta)$ can be cached from the
prior iteration). Unfortunately, in the era of ``Big Data''
$N$ may be on the order of petabytes and computing $L(\theta)$ at
each iteration may be prohibitively expensive.

Many methods have been proposed to tractably estimate \autoref{eq:likelihood}.
Firefly MC (FlyMC) belongs to a class of methods which approximate $L(\theta)$
using smaller tractable subsets of the total dataset. In FlyMC, auxilliary
``brightness'' variables are first introduced to decrease the number of
likelihood evaluations per iteration. The Markov chain state and auxilliary
variables are then successively Gibbs sampled. For certain inference problems,
FlyMC can provide a significant speedup (up to $12\times$ in our experiments,
\autoref{tab:reproduce}) over traditional MCMC even after accounting for
differences in expected sample size.

\subsection{Rationale for selecting the paper}

We chose the Firefly MC paper \cite{maclaurin2014firefly} because of the
ubiquity of MCMC sampling methods which see use not just in the fields of
machine learning and Bayesian statistics, but also in the fields of
computational physics, biology, and computational linguistics. Indeed, MCMC can
be used a universal inference method that is agnostic to the underlying
likelihood function and prior distribution. As a result, it already forms the
basis of many state-of-the-art probabilistic programming frameworks
\cite{prekopa2003probabilistic}.

Furthermmore, Firefly MC addresses the issue of tractable computations at
scale. With increasingly larger dataset sizes across all research and industry
domains, scalability has become an increasingly central concern and proven
tools such as MCMC have recently begun to receive much attention
\cite{korattikara2013austerity}.

\section{Theory}

Firefly Monte Carly (FlyMC) is a method which addressses the computational
problem of evaluating $L(\theta)$ for a large number of data points $N$ by
using exact Monte Carlo estimates of $L(\theta)$ computed over smaller,
tractable subsets. It works by augmenting the joint distribution with
hidden\emph{ brightness }variables $Z=\{z_{n}\in\left\{ 0,1\right\}
\}_{n=1}^{N}$to form a \emph{complete data likelihood}

\[
P(X,Z|\theta)=\prod_{n=1}^{N}P(x_{n}|\theta)P(z_{n}|x_{n},\theta)
\]

Like other auxilliary variable methods (e.g. Hamiltonian MC
\cite{brooks2011handbook}), we can recover the desired likelihoods simply
through marginalization

\[
\sum_{Z}P(X,Z|\theta)=\sum_{z_{1}}\dots\sum_{z_{N}}\prod_{n=1}^{N}P(|x_{n}|\theta)P(z_{n}|x_{n},\theta)=\prod_{n=1}^{N}P(|x_{n}|\theta)\sum_{z_{n}}P(z_{n}|x_{n},\theta)=L(\theta)
\]


In FlyMC, the brightness variables are chosen to have Bernoulli distribution

\begin{equation}
P(z_{n}|x_{n},\theta)=\left(\frac{L_{n}(\theta)-B_{n}(\theta)}{L_{n}(\theta)}\right)^{z_{n}}\left(\frac{B_{n}(\theta)}{L_{n}(\theta)}\right)^{1-z_{n}}\label{eq:brightness}
\end{equation}
where$B_{n}(\theta)$ is a lower bound on the likelihood satisfying

\begin{align}
 & 0\leq B_{n}(\theta)\leq L_{n}(\theta)\label{eq:bn-bound}\\
 & \prod_{n\in A}B_{n}(\theta)\text{ can be efficiently computed for any data subset }A\subset X\label{eq:bn-efficient}
\end{align}
\autoref{eq:bn-bound} is required for \autoref{eq:brightness} to be a valid
probability distribution. To see why \autoref{eq:bn-efficient} is necessary,
consider computing the complete data likelihood

\begin{align}
  P(X,Z|\theta) & =\prod_{n=1}^{N}P(x_{n}|\theta)P(z_{n}|x_{n},\theta)\nonumber \\
  & =\prod_{n=1}^{N}L_{n}(\theta)\left(\frac{L_{n}(\theta)-B_{n}(\theta)}{L_{n}(\theta)}\right)^{z_{n}}\left(\frac{B_{n}(\theta)}{L_{n}(\theta)}\right)^{1-z_{n}}\nonumber \\
  & =\prod_{x_{n}\in X_{bright}}\left(L_{n}(\theta)-B_{n}(\theta)\right)\prod_{x_{n}\in X_{dim}}\left(B_{n}(\theta)\right)\nonumber\\
  & =\prod_{n=1}^{N}B_{n}(\theta)\prod_{x_{n}\in X_{bright}}\frac{L_{n}(\theta)-B_{n}(\theta)}{B_{n}(\theta)}\label{eq:bright-dim-decomposition}
\end{align}
where we have defined the bright points $X_{bright}=\{x_{n}:z_{n}=1\}$ and dim
points $X_{dim}=\{x_{n}:z_{n}=0\}$. As a consequence of our choice for
\autoref{eq:brightness}, \autoref{eq:bright-dim-decomposition} decomposes into
two products where $\frac{L_{n}(\theta)-B_{n}(\theta)}{B_{n}(\theta)}$ only
needs to be evaluated for $x_{n}\in X_{bright}$. For illustration, we plot the
bright/dim decomposition of $L_n(\theta)$ in \autoref{fig:gap}, as well as show
an example $(\theta, z_n)$ trajectory.

\begin{figure}[H]
  \begin{centering}
    \includegraphics[scale=0.7]{Figures/gap-fig.png}
  \par\end{centering}
  \protect\caption{Graphical representation of the decomposition of
    $L_n$ into a $L_n - B_n$ part associated with bright variables $z_n = 0$
    and a $B_n$ part associated with dim variables $z_n = 0$ \cite{maclaurin2014firefly}}
  \label{fig:gap}
\end{figure}

\autoref{eq:bright-dim-decomposition} also illustrates the payoff from assuming
\autoref{eq:bn-efficient}: by assuming $\prod_{n=1}^{N}B_{n}(\theta)$ term in
\autoref{eq:bright-dim-decomposition} is efficient, the overall computational
complexity of evaluating the complete likelihood $P(X,Z|\theta)$ is determined
by $\#X_{bright}$.

\subsection{Markov chain implementation}

Samples $(\theta, \vec{z}) \sim (P(\theta | X), P(Z|X,\theta))$ can be
generated using Gibbs sampling because of iid assumptions amongst the $X$ and
lack of interdependence amongst the $Z$. Given current $\theta^{(t)}$ and
$\vec{z}^{(t)}$, we first fix the parameters $\theta$ and sample the brightness
variables $z_n$ with Bernoulli probability $\frac{L_n(\theta) -
B_n(\theta)}{L_n(\theta)}$. Then, the brightnesses $z_n$ are fixed and
the Markov chain is stepped using Metropolis-Hastings
\cite{chib1995understanding} or more complex steppers such as
Metropolis-adjusted Langevin dynamics \cite{roberts2002langevin} when
the likelihood is differentiable.

The resampling of the brightness variables at each iteration cause
each data point to ``blink'' bright and dim across iterations, inspiring
the name ``Firefly'' given to this method.

\subsubsection{Implicit sampling}

One possible criticism of the method described above is that direct
sampling of $z_{n}$ from $N$ Bernoulli distributions, each
with probability $\frac{L_{n}(\theta)-B_{n}(\theta)}{L_{n}(\theta)}$,
would again require $N$ evaluations of $L_{n}(\theta)$. This appears to
mitigate any savings obtained by FlyMC.

Fortunately, this can be mitigated through implicit sampling. Instead of
recomputing Bernoulli probabilities and directly sampling the $N$ $z_n$s, a
second MH-MCMC is used for sampling brightnesses. The motivation is that many
$z_{i}=0$ ideally, hence it makes sense to only consider proposals where each
dim point has a small $q_{d\to b}\in[0,1]$ probability of becoming bright.
As computing the acceptance probability requires likelihoods only need to
be evaluated for the brightness variables proposed to change state, this
could significantly reduce the number of likelihood evaluations if few
brightness variables change state across successive Gibbs iterations.

\subsection{Theoretical performance analysis}

FlyMC's speedup over a traditional $O(N)$ likelihood evaluation is
$\frac{N}{\#X_{bright}}$ per iteration. However, since the brightness variables
$z_{n}$are themselves, to understand the performance improvements we consider
the expected number of bright points $E[\#X_{bright}]$.

Note that for any point $x_{n}$, \autoref{eq:brightness} shows that the
probability $x_{n}$ is bright is given by
$\frac{L_{n}(\theta)-B_{n}(\theta)}{L_{n}(\theta)}$. Hence, the number of
bright points is given by

\begin{equation}
  E[\#X_{bright}]=\sum_{n=1}^{N}E[z_{n}]=\sum_{n=1}^{N}\int P(\theta|X)\frac{L_{n}(\theta)-B_{n}(\theta)}{L_{n}(\theta)}d\theta\label{eq:num-bright}
\end{equation}


This says that the number of bright points (and hence the speedup
achieved by FlyMC) is related to the gap between the true likelihood
$L_{n}(\theta)$ and the lower bound $B_{n}(\theta)$, weighted by
the posterior $P(\theta|X)$.

This result makes intuitive sense. Consider the extreme case where
for all $n$: $B_{n}(\theta)=0$. Then $P(z_{n}=1|x_{n},\theta)=1$
so every data point is bright (i.e. $X=X_{bright}$) and \autoref{eq:bright-dim-decomposition}
reduces to evaluating the full dataset likelihood $\prod_{n=1}^{N}L_{n}(\theta)$
as usual.

In the other extreme, if $B_{n}(\theta)=L_{n}(\theta)$ so all data
points are dim. At first it appears that FlyMC counterintuitively
offers a $\frac{N}{\#X_{bright}}=\frac{N}{0}=\infty$speedup. However,
considering \autoref{eq:bright-dim-decomposition} reveals that what is
computed is $\prod_{n=1}^{N}B_{n}(\theta)=\prod_{n=1}^{N}L_{n}(\theta)$,
which by assumption \autoref{eq:bn-efficient}can be computed efficiently.
But then computing $L(\theta)=\prod_{n=1}^{N}L_{n}(\theta)$ is efficient
and hence is no longer $O(N)$, contradicting our earlier assumptions.


\subsection{Discussion on the lower bound $B_{n}(\theta)$}

The integral role played by the lower bound $B_{n}(\theta)$ makes
it an important topic of investigation. In this section, we investigate
how reasonable and justified are the assumptions required for developing
FlyMC's theory.

One of our assumptions (\autoref{eq:bn-efficient}) was that computation
of $\prod_{n=1}^{N}B_{n}(\theta)$ be efficient new $\theta$. For
example, choosing $B_{n}(\theta)$ to be exponential family will make
computing $\prod_{n=1}^{N}B_{n}(\theta)$ for each new $\theta$ be
$O(1)$ because

\begin{align*}
B_{n}(\theta) & \propto\exp\left(\left\langle\eta_{n},T(\theta)\right\rangle\right)\\
\prod_{n=1}^{N} & B_{n}(\theta)\propto\exp\left(\left\langle\sum_{n=1}^{N}\eta_{n},T(\theta)\right\rangle\right)
\end{align*}
and $\sum_{n=1}^{N}\eta_{n}$ can be evaluated once and cached. We
believe that this assumption is quite restrictive and have had some
difficulty coming up with functional forms which are not exponential
family that satisfy this assumption.

The other assumption (\autoref{eq:bn-bound}) required $B_{n}(\theta)$
be a non-negative lower bound for $L_{n}(\theta)$. This is trivially
satisfied by setting $B_{n}(\theta)=0$, but to be practical we should
try to find a lower bound with the smallest gap possible. Several
forms of bounds exist for commonly used likelihoods; the original
authors consider the Jaakola and Jordan bound on the log logistic
function. However, this requirement is quite restrictive and unrealistic
for more complex use cases. For example, if $L_{n}(\theta)$ is given
by some complicated Bayes net or neural network, then a valid $B_{n}(\theta)$
for use with FlyMC is not immediately obvious.


\subsubsection{MAP-tuning the lower bound}

In certain cases (e.g. Jaakola and Jordan bound on log logistic),
$B_{n}$ is part of a parametric family of lower bounds \textbf{$\left\{ B_{n}(\cdot,\xi)\right\} _{\xi}$}where
$\xi$ is a free parameter. Since the number of bright points determines
the speedup offered by FlyMC, \autoref{eq:num-bright} suggests that we
should choose $\xi$ to minimize $E\left[\frac{L_{n}(\theta)-B_{n}(\theta)}{L_{n}(\theta)}\right]$
for each datapoint $n$ where the expectation is taken over the posterior
distribution $P(\theta|X)$.

The authors of FlyMC propose a \emph{MAP-tuned FlyMC} variant where
the posterior expectation $E\left[\frac{L_{n}(\theta)-B_{n}(\theta)}{L_{n}(\theta)}\right]$
is replaced with the MAP point estimate $\frac{L_{n}(\theta_{MAP})-B_{n}(\theta_{MAP})}{L_{n}(\theta_{MAP})}$
and$\xi=\text{argmin}_{\xi}L_{n}(\theta_{MAP})-B_{n}(\theta_{MAP})$.$\theta_{MAP}=\text{\text{argmax}}_{\theta}P(\theta|X)$
can be found using stochastic gradient descent to handle large data-set
concerns.

Our opinions about this method are mixed. While MAP tuning should
provide a tighter lower bound than no tuning, approximating the posterior
with a delta distribution centered at $\theta_{MAP}$seems suspicious.
Other methods which could be considered here include first generating
some posterior samples using an untuned chain or MCMC on a subset
of the data, then tuning $\xi$over the posterior samples.


\section{Implementation}

FlyMC augments traditional MCMC by introducing brightness variables
$Z$ which are Gibbs sampled along with the original chain's state
$\theta$. At a high level, the algorithm consists of the following
steps:
\begin{enumerate}
  \item Initialize $\theta^{(0)}$
  \item For $t=1,\cdots,N_{iter}$

    \begin{enumerate}
      \item For $n=1,\cdots,N$: sample $z_{n}^{(t)}\sim\text{Bernoulli}\left(\frac{L_{n}(\theta^{(t)})-B_{n}(\theta^{(t)})}{L_{n}(\theta^{(t)})}\right)$
        with $\theta=\theta^{(t)}$fixed
    \end{enumerate}
  \item Propose $\theta^{(t+1)}\sim q(\theta^{(t+1)}|\theta^{(t)})$
  \item Compute acceptance probability $A(\theta^{(t+1)}|\theta^{(t)})=\min\left\{ 1,\frac{q(\theta^{(t)}|\theta^{(t+1)})P(X,Z|\theta^{(t+1)})P(\theta^{(t+1)})}{q(\theta^{(t+1)}|\theta^{(t)})P(X,Z|\theta^{(t)})P(\theta^{(t)})}\right\} $
  \item Repeat from step 2 until chain has mixed, yielding a single sample
    $z_{n}^{(\infty)}$
\end{enumerate}
In step 4, the complete data likelihood is computed using \autoref{eq:bright-dim-decomposition}
and hence only requires evaluating the likelihood over $X_{bright}$.

\subsection{Provided reference software}

Reference code is provided by the authors%
\footnote{https://github.com/HIPS/firefly-monte-carlo}, which provides
implementations FlyMC for logistic regression using MH-MCMC, softmax using
Langevin dynamics, and sparse linear regression using slice sampling. The
reference implementation includes an implicit sampling scheme for sampling
brightness variables $z_{i}$.


\subsection{Our contributions to the project}

However, the only full example provided is a logistic regression example
on toy data and is insufficient for reproducing the results reported
in the paper. We forked
he authors' code \footnote{https://github.com/feynmanliang/firefly-monte-carlo}
and added our own modifications, most importantly:
\begin{enumerate}
  \item Support for MAP-tuning of the lower bounds, using scipy.optimize
    for MAP estimation
  \item Implementation of regular full-dataset MCMC, which is achieved by
    fixing $\forall i:z_{i}=1$
  \item Improved numerical overflow handling in \texttt{LogisticModel}
  \item Instrumentation for counting log-likelihood evaluations and outputting
    traces of chain state and log likelihood per iteration
  \item Integration, parameter tuning, and reproduction of MNIST Logistic
    Regression, CIFAR-10 Softmax Classification, and Robust Linear Regression
    experimental results
\end{enumerate}

We also fixed a significant bug in some caching code provided with
the reference implementation and submitted our bugfix back upstream
\footnote{https://github.com/HIPS/firefly-monte-carlo/pull/1}. The problem was
that computations of $\left\{
  \frac{L_{n}(\theta)-B_{n}(\theta)}{B_{n}(\theta)}:n\in idx\right\} $were
being cached for vectors $\theta$ and $idx$, but that caching was
performed over the entire $idx$ vector rather than elementwise. For
example, if $idx2\subsetneq idx$, then even though $\left\{ \frac{L_{n}(\theta)-B_{n}(\theta)}{B_{n}(\theta)}:n\in idx2\right\} \subset\left\{ \frac{L_{n}(\theta)-B_{n}(\theta)}{B_{n}(\theta)}:n\in idx\right\} $
the reference implementation would still result in a cache miss because
$idx2\neq idx$. This bug causes the number of likelihood evaluations
to be twice the number of proposed bright points $\#X_{bright}$at
each iteration, which means that FlyMC will only offer speedups if
$\#X_{bright}<\frac{N}{2}$.


\section{Reproduction experiments}\label{sec:experiments}

We conducted the following three experiments:
\begin{itemize}
  \item Logistic regression: For this particular task, we tested we tested
    FlyMC's preformance for the task of classifying 7s and 9s on MNIST,
    with prior $P(\theta)\sim\mathcal{N}(0,I)$.
  \item Softmax classification: For this task, we tested FlyMC's ability to
    fit a softmax classification model on three CIFAR-10 classes (airplane,
    automobile and bird) using Langevin dynamics
  \item Robust linear regression: For logistic regression task, we generated
    synthetic data and evaluated the performance of FlyMC in comparison
    to regular MCMC.
\end{itemize}
The first two of these three experiments were data-sets used in the
paper. However, the OPV dataset used in the robust linear regression
was not publically available in a convenient format. This also gave us
an opportunity to explore FlyMC's performance fitting a model against
data where the true model is known.

\subsection{Results of the three methods}

In this section we will need to discover whether the reductions in likelihood evaluations per iteration that had been
obtained in FlyMC would dominate the increased burn-in period that is required when sampling using fire-fly Monte Carlo.

From figure (c), we can see that the number of log-likelihood evaluations at a given iteration
is constant under the MH-MCMC sampler for Logistic regression on MNIST. Approximately, 12,000 evaluations are
computed at each iteration. For soft-max classification, figure (c) , this number of evaluations is also constant at 3000.
In contrast, far fewer likelihood evaluations are required under both the flyMC and flyMap models/ In figure (c) we can see that
both flymap and flymc compute less than a 12th of the likelihood computations evaluated by the MCMC sampler.
The trend is less marked for both soft-max classification and robust regression as can be seen in the respective figures (c), where
FlyMC and FlyMAP seem to return more modest reductions of aroud  1/3 and 1/6 of the likelihoods respectively.

If we had reached the stationary distibution of a markov Chain, this would represent a significant reduction in the
likelihoods that one would need to compute. However, to an extent flymap's benefits from reduced likelihood computations
will be mitigated by a slower burn in period and also more dependent samples. This means that the sampling chains for
FlyMc and FlyMap would have to be run for longer to generate accurate samples.

The plots for the negative log posterior (b) gives some indication of the burn-in period, since log-likelihoods for the
sampled paramaters will only start to stop dropping, when the stationary distribution of the Markov Chain has been reached.
For logisitic regression, it seems as though these likelihoods that are reached at the 2000th iteration are only reached at the 4000th
iteration for both flymc and flymap, which seems to suggest a burn in that is around twice as slow as regular MCMC.
For logistic regression, a reasonable burn in period would be 200 iterations, whereas it seems as though 400 iterations would
do better justice to the fireFly Monte Carlo methods. For robust regression, these figures seem to be 200 and 350 respectively for
mcmc and flymc/flymap.

Plots of the auto-correlations can further complement the picture presented by the log-likelihood plots,
since they can give an idea of the spacing between dependent samples, which can also approximate for
a particular burn in period. The auto-correlation plots confirm our suspicion that fire-fly MC methods produce samples that tend
to be more dependent, however they do little to arbitrate int he dispute of what term will dominate when perfoming FlyMC:
fewer likelihood evaluations per iteration or greater burn-in periods. So far, it seems as though the likelihood reductions
are the dominant term in these computations.

To summarise, exactly same sorts of trends were found in our generated tests as were found in the paper by Ryan Adams.\footnote{https://github.com/HIPS/firefly-monte-carlo%}.
MCMC has better mixing ( as demonstrated through autocorrelation), and better likelihoods at a given iteration.
Though FlyMC and FlyMap show worse mixing, and have lower negative log likelihoods at
a given iteration, crucially they use fewer log-likelihood updates at each iteration and are found to be very competitive samplers.
 
Table~\ref{}Table~\ref{tb:ess}. The results are based using, the corresponding
\subsection{Reproducing Table 1 from \ref{maclaurin2014firefly}}

\todo{Less exposition about ESS, more about trading off burn in for less evaluations
and how to measure the effect of burn in}

Crucially, however, the effectiveness of MC interpolation depends
on the effective sample size for a given number of iterations. If FlyMc is to
deliver the improvements in 1000 iteration.

We can calculate a quantity that determines the effective sample rate by
choosing a log-likelihod value, L, and computing the number of iterations MCMC,
FlyMap and FlyMC took to reach that log likelihood. Suppose these numbers were
M, FM and FMC respectively for each of MCMC, FlyMap and FlyMC. Then for FlyMap,
the effective sample rate is given by:  (FM/M)*average number of likelihood
evaluations up until FM. I present our estimates of these evaluations in
\autoref{tab:reproduce}. The results are based using, the corresponding
MCMC sampler.

Following \cite{cowles1996markov}, we can quantify slower burn-in
\autoref{tab:reproduce} shows the effective sample size (ESS) per 1000 iterations of
regular MCMC, untuned MCMC and MAP-tuned FlyMC for the three experiments.
\begin{table}[H]
  \centering
  \caption{Reproduction of the experiments reported in \cite{maclaurin2014firefly}. We did not
  reproduce the robust regression with slice sampling experiments because the OPV dataset used
  by the authors is not available in an easily consumable format.}
  \label{tab:reproduce}
  \begin{tabular}{ccp{3.2cm}p{2.3cm}p{2.5cm}}
    \toprule
    Data Set & Algorithm & Average likelihood queries per iteration & ESS per 1000 iterations & Relative Speedup \\
    \midrule
    \multirow{3}{*}{Logistic Regression}
    & Regular MCMC     & 12214  &  3.6 & (1) \\
    & Untuned FlyMC    & 6252   &  0.5 & 0.271 \\
    & MAP-Tuned FlyMC  & 207    &  0.6 & 9.834 \\
    \hline
    \multirow{3}{*}{Softmax classification}
    & Regular MCMC     & 18000  &  7.1 & (1)\\
    & Untuned FlyMC    & 7997   &  4.0 & 1.268 \\
    & MAP-Tuned FlyMC  & 662    &  3.3 & 12.638 \\
    \hline
    \multirow{3}{*}{Robust Regression}
    & Regular MCMC     & NA  &  NA & NA \\
    & Untuned FlyMC    & NA  &  NA & NA \\
    & MAP-Tuned FlyMC  & NA  &  NA & NA \\
    \bottomrule
  \end{tabular}
\end{table}
Our results in \autoref{tab:reproduce} show that MAP-tuned FlyMC performs well
and achieves rougly an order of magnitude relative speedup in all cases.
Untuned FlyMC, however, can be as much as $5\times$ slower. As evidenced by
the increased number of likelihood queries, this slowdown is caused by increased
likelihood evaluations while attaining the same ESS. We suspect the underlying cause
is due to the larger gap in the untuned lower bound, which following
\autoref{eq:num-bright} leads to more bright points.

\begin{figure}[htbp]
  \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics[scale=0.35]{Figures/final/logi_corr.png}
    \caption{Autocorrelation}
  \end{subfigure}
  \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics[scale=0.35]{Figures/final/logi_lik.png}
    \caption{Negative log posterior}
  \end{subfigure}
  \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics[scale=0.35]{Figures/final/logi_numlik.png}
    \caption{Number likelihood evaluations}
  \end{subfigure}
  \caption{Logistic regression binary classification on MNIST with MH-MCMC}
\end{figure}

\begin{figure}[htbp]
  \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics[scale=0.35]{Figures/final/soft_corr.png}
    \caption{Autocorrelation}
  \end{subfigure}
  \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics[scale=0.35]{Figures/final/soft_lik.png}
    \caption{Negative log posterior}
  \end{subfigure}
  \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics[scale=0.35]{Figures/final/soft_numlik.png}
    \caption{Number likelihood evaluations}
  \end{subfigure}
  \caption{Softmax 3-way classification on CIFAR-10 with Langevin dynamics}
\end{figure}

\begin{figure}[htbp]
  \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics[scale=0.35]{Figures/final/reg_corr.png}
    \caption{Autocorrelation}
  \end{subfigure}
  \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics[scale=0.35]{Figures/final/reg_lik.png}
    \caption{Negative log posterior}
  \end{subfigure}
  \begin{subfigure}[t]{0.32\textwidth}
    \includegraphics[scale=0.35]{Figures/final/reg_numlik.png}
    \caption{Number likelihood evaluations}
  \end{subfigure}
  \caption{Robust regression on synthesized data with slice sampler}
\end{figure}




\section{Conclusion}

From this practical, we saw how Firefly MC introduces auxiliary ``brightness''
variables to control the computational complexity of each MC iteration while
still maintaining an exact estimator for the full likelihood. We saw that
the auxilliary variables were defined using a lower bound $B_n(\theta)$ who's
tightness to $L_n(\theta)$ is inversely proportional to the probability
of a point being bright. We saw MAP tuning as ome way to choose lower bounds
minimize this gap, which in turn minimizes the number of bright points and
hence maximizes the speedups offered by FlyMC.

Our experimental results from \autoref{sec:experiments} yielded similar trends
on all data sets, tasks, and Markov chain steppers (e.g.\ MH, Langevin, slice
sampler) considered. In all cases, using FlyMC results in a decrease in the
average number of likelihood evaluations due to how the brightness
probabilities are defined in \autoref{eq:brightness}. At the same time, ESS
also decreases because subsets rather than the full dataset are used for
computing acceptance probabilities.

Comparing the ratio of ESS over average likelihood queries can give us a sense
of relative speedup over regular MCMC accounting for the longer burn in time.
According to \autoref{tab:reproduce}, we see that untuned FlyMC may perform
slightly better than regular MCMC but may also be relatively slower. In
contrast, the MAP tuned FlyMC algorithm consistently achieves speedups $\approx
10\times$. This highlights the significant impact of the lower bound's gap on
performance and emphasizes the importance of choosing the lower bound properly.
Our results in \autoref{tab:reproduce} are very close to those reported in
Table 1 of \ref{maclaurin2014firefly}, indicating that we were successful
in replicating the results reported in the original paper.

Through completing this practical, we have made a number of contributions
(Github pull requests) back upstream to Harvard Intelligent Probabilistic
Systems Group's code repository which address sevaral important bugs and
optimizations. In particular, we optimize the likelihood caches to work
elementwise, fix overflow prevention in various areas of the code,
and provide integration for MAP-tuning using \texstttt{scipy.optimize}.

Many extensions of the work we have presented are possible. One particularly
important experiment would be to tune the lower bounds over multiple parameter
values sampled from the posterior rather than the single MAP estimate. This
would ensure a low number of expected bright points, even if we are possibly
far away from the MAP estimate. Given the significant performance difference
between MAP-tuned and untuned FlyMC, we expect tuning lower bounds in this
manner to yield even lower numbers of bright points and hence greater speedups
over traditional MCMC.

Another direction for investigation is on the lower bounds $B_n$. The
assumptions made in assumptions 1 and 2 on $B_n$ are required
for formulating FlyMC, and the authors do a good first pass discussion about
using exponential families for $B_n$. However, it may be interesting to
consider other functional forms for $B_n$ such that $\prod_{n=1}^N B_n(\theta)$
is cheap to compute. Furthermore, it is often the case that we are working with
likelihoods $L(\theta)$ which do not have a well-known lower bound (e.g.\
$L(\theta)$ could be parameterized by a deep neural network). In these
situations, one would like any form of lower bound which is non-zero. Alternatively,
one could investigate what happens when approximate bounds are used for $B_n(\theta)$
where cite the 0 <= Bn <= 1 does not hold for all $\theta$.

Finally, we would like to mention that although the motivation for this work
is computing on big datasets with large $N$, most experiments presented here
and in the paper were small and run on a single machine. For FlyMC to truly be
impactful in big data applications, an implementation on a distributed
computing platform (e.g.\ Spark, Hadoop) which demonstrates tractable MCMC on
large datacenter-scale datasets would be a convincing and immediately useful
line of work.


\bibliographystyle{alpha}
\nocite{*}
\bibliography{refs.bib}

\onecolumn

\end{document}
